{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "loyEE5HHlhNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QRsFjE9-dK4i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import Tuple, List, Union, Iterable\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torchmetrics.functional import char_error_rate\n",
        "\n",
        "\n",
        "def rand(seed=42):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "rand()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KS5CQ4Vt-_0",
        "outputId": "69501651-902a-4e52-c592-38c286b07a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q3WUH4VCdU9"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/'Colab Notebooks'/'Тинькофф Образование'/CCPD2019-dl1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaDAHAbicqlT"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Объявление класса-датасета CCPD19"
      ],
      "metadata": {
        "id": "jPpGeM-QJwn4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XMm6uIxocgvv"
      },
      "outputs": [],
      "source": [
        "class CCPD19(Dataset):\n",
        "    def __init__(self, img_dir: str, transform: bool = True, \n",
        "                 img_size: Tuple[int, int] = (100, 32)) -> None:\n",
        "        \"\"\"\n",
        "        Инициализация датасета\n",
        "        :param img_dir: Путь до директории с изображениями\n",
        "        :param transform: Флаг для преобразования данных. Если значение True, тогда будет изменен цвет и размер фотографий\n",
        "        :param img_size: Размер преобразованного изображения\n",
        "        \"\"\" \n",
        "        all_files = next(os.walk(img_dir))[2]\n",
        "        self.img_labels = list(map(lambda x: x.split('.')[0].split('-'), all_files))\n",
        "        self.img_labels = np.append(np.reshape(all_files, (len(all_files), 1)), self.img_labels, axis=1)\n",
        "        self.img_dir = img_dir\n",
        "        self.img_size = img_size\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, List]:\n",
        "        \"\"\"\n",
        "        Метод для получения наблюдения по idx\n",
        "        :param idx: Индекс искомого наблюдения\n",
        "        :return: Кортеж с изображением и его меткой\n",
        "        \"\"\"\n",
        "        # TODO: Add converter to labels\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels[idx, 0])\n",
        "        image = cv2.imread(img_path)\n",
        "        label = self.img_labels[idx, 2]\n",
        "        if self.transform:\n",
        "            image = cv2.resize(image, self.img_size)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = torch.Tensor(image).to(device)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Возвращает количество наблюдений в датасете\n",
        "        :return: Количество наблюдений\n",
        "        \"\"\"\n",
        "        return len(self.img_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Объявление класса-конвертера"
      ],
      "metadata": {
        "id": "99PP2wfFKMgi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UQG8buBd4x0L"
      },
      "outputs": [],
      "source": [
        "class Converter:\n",
        "    def __init__(self, symbols: List) -> None:\n",
        "        \"\"\"\n",
        "        Кодировщик символов к цифрам. Также преобразует данные к Тензорам pytorch.\n",
        "        :param symbols: Набор символов\n",
        "        \"\"\"\n",
        "        self.encode_mapping = {}\n",
        "        for i, sym in enumerate(symbols):\n",
        "            self.encode_mapping[sym] = i + 1\n",
        "        \n",
        "        self.decode_mapping = {0: '-'}\n",
        "        for key, value in self.encode_mapping.items():\n",
        "            self.decode_mapping[value] = key\n",
        "    \n",
        "    def encode(self, text: Union[str, Iterable]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Кодирование текста и приведение к виду удобного для вычисления CTCLoss.\n",
        "        :param text: Текст для кодирования\n",
        "        :return: (Текст, Размеры текстов)\n",
        "        \"\"\"\n",
        "        if isinstance(text, str):\n",
        "            text = [\n",
        "                self.encode_mapping[sym] \n",
        "                for sym in text\n",
        "            ]\n",
        "            length = [len(text)]\n",
        "            return torch.IntTensor(text).to(device), torch.IntTensor(length).to(device)\n",
        "        elif isinstance(text, Iterable):\n",
        "            length = [len(t) for t in text]\n",
        "            text = [self.encode(t)[0] for t in text]\n",
        "            return torch.stack(text).to(device), torch.IntTensor(length).to(device)\n",
        "    \n",
        "    def decode(self, seq: Iterable) -> List[str]:\n",
        "        \"\"\"\n",
        "        Декодирование последовательности чисел в слово\n",
        "        :param seq: Последовательность чисел\n",
        "        :return: Декодируемое слово\n",
        "        \"\"\"\n",
        "        if isinstance(seq, torch.Tensor):\n",
        "            seq = seq.cpu().numpy()\n",
        "        if len(seq.shape) == 1:\n",
        "            text = [self.decode_mapping[s] for s in seq]\n",
        "        elif len(seq.shape) == 2:\n",
        "            text = [self.decode(seq[i]) for i in range(len(seq))]\n",
        "        return text\n",
        "    \n",
        "    def clean(self, text: Union[torch.Tensor, List], \n",
        "              blank: int = 0) -> Union[torch.Tensor, List]:\n",
        "        \"\"\"\n",
        "        Метод для очистки полученой последовательности символов (кодов) из\n",
        "        нейронной сети. Удаляет пустые символы и берет последний не пустой код,\n",
        "        если коды идут подряд без пробелов.\n",
        "        :param text: Батч с последовательностями кодов\n",
        "        :param blank: Число, отвечающее за код пропуска, пробела\n",
        "        :return: Очищенная последовательность из 7 кодов\n",
        "        \"\"\"\n",
        "        if isinstance(text, torch.Tensor):\n",
        "            res = torch.zeros((text.shape[0], 7), dtype=torch.int8).to(device)\n",
        "            for i in range(len(text)):\n",
        "                k = 0\n",
        "                for j in range(len(text[i]) - 1):\n",
        "                    if text[i, j].item() != blank and text[i, j+1].item() == blank:\n",
        "                        if k >= 7: \n",
        "                            break\n",
        "                        res[i, k] = text[i, j]\n",
        "                        k += 1\n",
        "                if text[i, -1].item() != blank:\n",
        "                    res[i, -1] = text[i, -1]\n",
        "        else:\n",
        "            res = []\n",
        "            for i in range(len(text)):\n",
        "                for j in range(len(text[i]) - 1):\n",
        "                    if text[i][j] != blank and text[i][j+1] == blank:\n",
        "                        res.append(text[i][j])\n",
        "                if text[i][-1] != blank:\n",
        "                    res.append(text[i][-1])\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подгрузка данных"
      ],
      "metadata": {
        "id": "iHHzo-6yKWNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K2PXqh4w50OV"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = 'CCPD2019-dl1/train'\n",
        "TEST_PATH = 'CCPD2019-dl1/test'\n",
        "\n",
        "train = CCPD19(TRAIN_PATH)\n",
        "test = CCPD19(TEST_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим символы, которые используются в тренировочной выборке на автомобильных номерах"
      ],
      "metadata": {
        "id": "3XLYRi54J5O6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "bwZcgawfR8Jt",
        "outputId": "8d3fbbe1-1459-4712-9b7f-0e9a136e2360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789ABCDEFGHJKLMNOPQRSTUVWXYZ云京冀吉宁川新晋桂沪津浙渝湘琼甘皖粤苏蒙藏豫贵赣辽鄂闽陕青鲁黑'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "all_files = next(os.walk(TRAIN_PATH))[2]\n",
        "labels = list(map(lambda x: x.split('.')[0].split('-')[1], all_files))\n",
        "symbols = sorted(list(set(''.join(labels))))\n",
        "''.join(symbols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEpJOm88ER3S"
      },
      "source": [
        "# Создание и обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Объявление архитектуры Нейронной сети"
      ],
      "metadata": {
        "id": "xqkwxI9QKrpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "26VgmfDnlsPO"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, \n",
        "                 kernel_size: Tuple[int, int], stride: int, padding: int, \n",
        "                 batch_norm: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        Инициализация повторяющегося слоя свертки\n",
        "        :param in_channels: Количество входных каналов\n",
        "        :param out_channels: Количество выходных каналов\n",
        "        :param kernel_size: Размер ядра\n",
        "        :param stride: Размер шага\n",
        "        :param padding: Размер отступа от рамки\n",
        "        :param batch_norm: Флаг использования BatchNorm\n",
        "        \"\"\"\n",
        "        super(Conv, self).__init__()\n",
        "\n",
        "        self.normalize = batch_norm\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, images: torch.Tensor) -> List:\n",
        "        \"\"\"\n",
        "        Прямой проход по слою свертки\n",
        "        :param images: Батч с изображениями - наблюдениями\n",
        "        :return: Результат прохода по сети\n",
        "        \"\"\"\n",
        "        output = self.conv(images)\n",
        "        if self.normalize:\n",
        "            output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aR0S42egEb0A"
      },
      "outputs": [],
      "source": [
        "class CRNN(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        \"\"\"\n",
        "        Инициализация слоев нейронной сети\n",
        "        :param num_classes: Количество символов-классов для предсказывания\n",
        "        \"\"\"\n",
        "        super(CRNN, self).__init__()\n",
        "        \n",
        "        # Convolutional Layers\n",
        "        self.conv0 = Conv(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        \n",
        "        self.conv1 = Conv(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        \n",
        "        self.conv2 = Conv(in_channels=128, out_channels=256, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.conv3 = Conv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
        "        \n",
        "        self.conv4 = Conv(in_channels=256, out_channels=512, kernel_size=(3, 3), stride=1, padding=1, batch_norm=True)\n",
        "        \n",
        "        self.conv5 = Conv(in_channels=512, out_channels=512, kernel_size=(3, 3), stride=1, padding=1, batch_norm=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
        "        \n",
        "        self.conv6 = Conv(in_channels=512, out_channels=512, kernel_size=(2, 2), stride=1, padding=0)\n",
        "\n",
        "        # Recurrent Layers\n",
        "        self.lstm0 = nn.LSTM(input_size=512, hidden_size=256, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "        # Transcription Layers\n",
        "        self.linear0 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "    \n",
        "    def forward(self, images: torch.Tensor) -> List:\n",
        "        \"\"\"\n",
        "        Прямой проход по нейронной сети\n",
        "        :param images: Батч с изображениями - наблюдениями. Shape: [b, h, w]\n",
        "        :return: Результат прохода по сети\n",
        "        \"\"\"\n",
        "        images = torch.unsqueeze(images, 1)         # [b, 1, 32, 100]\n",
        "\n",
        "        # Convolutional Layers\n",
        "        output = self.conv0(images)                 # [b, 64, 32, 100]\n",
        "        output = self.pool0(output)                 # [b, 64, 16, 50]\n",
        "\n",
        "        output = self.conv1(output)                 # [b, 128, 16, 50]\n",
        "        output = self.pool1(output)                 # [b, 128, 8, 25]\n",
        "\n",
        "        output = self.conv2(output)                 # [b, 256, 8, 25]\n",
        "\n",
        "        output = self.conv3(output)                 # [b, 256, 8, 25]\n",
        "        output = self.pool2(output)                 # [b, 256, 4, 25]\n",
        "\n",
        "        output = self.conv4(output)                 # [b, 512, 4, 25]\n",
        "\n",
        "        output = self.conv5(output)                 # [b, 512, 4, 25]\n",
        "        output = self.pool3(output)                 # [b, 512, 2, 25]\n",
        "\n",
        "        output = self.conv6(output)                 # [b, 512, 1, 24]\n",
        "\n",
        "        # TODO: Add packed/padded sequence\n",
        "        # Map to sequence\n",
        "        output = torch.squeeze(output, 2)           # [b, 512, 24]\n",
        "        output = torch.permute(output, (0, 2, 1))   # [b, 24, 512]\n",
        "\n",
        "        # Recurrent Layers\n",
        "        output, _ = self.lstm0(output)\n",
        "\n",
        "        # Transription Layers\n",
        "        b, w, c = output.size()\n",
        "        output = output.reshape(b * w, c)           # [b * 24, 512]\n",
        "        output = self.linear0(output)\n",
        "        output = output.reshape(b, w, -1)           # [b, 24, num_classes]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "U8RpbM9KKx1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "06ZYsF3Pym1t"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, converter):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (images, labels) in enumerate(dataloader):\n",
        "        batch_size = images.size(0)\n",
        "        labels, labels_length = converter.encode(labels)\n",
        "\n",
        "        preds = model(images).log_softmax(2)\n",
        "        preds = torch.permute(preds, (1, 0, 2))\n",
        "        preds_length = torch.IntTensor([preds.size(0)] * batch_size).to(device)\n",
        "    \n",
        "        loss = loss_fn(preds, labels, preds_length, labels_length)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(images)\n",
        "            print('loss: {:>7f} [{:>5d}/{:>5d}]'.format(loss, current, size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SsRwWm_twdSz"
      },
      "outputs": [],
      "source": [
        "converter = Converter(symbols)\n",
        "\n",
        "num_classes = len(symbols) + 1\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "epochs = 5\n",
        "\n",
        "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "model = CRNN(num_classes).to(device)\n",
        "\n",
        "loss_fn = nn.CTCLoss()\n",
        "# optimizer = torch.optim.Adadelta(model.parameters(), learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbhTOSq90bYl",
        "outputId": "04aea3c6-e5c9-4f7a-a58b-4832a2b91af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------------------------\n",
            "loss: 11.630688 [    0/199980]\n",
            "loss: 2.613410 [ 6400/199980]\n",
            "loss: 2.611552 [12800/199980]\n",
            "loss: 2.409519 [19200/199980]\n",
            "loss: 1.575177 [25600/199980]\n",
            "loss: 0.302296 [32000/199980]\n",
            "loss: 0.107133 [38400/199980]\n",
            "loss: 0.060344 [44800/199980]\n",
            "loss: 0.072794 [51200/199980]\n",
            "loss: 0.057137 [57600/199980]\n",
            "loss: 0.037419 [64000/199980]\n",
            "loss: 0.032471 [70400/199980]\n",
            "loss: 0.054683 [76800/199980]\n",
            "loss: 0.035017 [83200/199980]\n",
            "loss: 0.021379 [89600/199980]\n",
            "loss: 0.027473 [96000/199980]\n",
            "loss: 0.007931 [102400/199980]\n",
            "loss: 0.017162 [108800/199980]\n",
            "loss: 0.033262 [115200/199980]\n",
            "loss: 0.003788 [121600/199980]\n",
            "loss: 0.013603 [128000/199980]\n",
            "loss: 0.006803 [134400/199980]\n",
            "loss: 0.035787 [140800/199980]\n",
            "loss: 0.001346 [147200/199980]\n",
            "loss: 0.001574 [153600/199980]\n",
            "loss: 0.002771 [160000/199980]\n",
            "loss: 0.017202 [166400/199980]\n",
            "loss: 0.024923 [172800/199980]\n",
            "loss: 0.024012 [179200/199980]\n",
            "loss: 0.001675 [185600/199980]\n",
            "loss: 0.005182 [192000/199980]\n",
            "loss: 0.008821 [198400/199980]\n",
            "Epoch 2\n",
            "----------------------------------\n",
            "loss: 0.003012 [    0/199980]\n",
            "loss: 0.006423 [ 6400/199980]\n",
            "loss: 0.000715 [12800/199980]\n",
            "loss: 0.010131 [19200/199980]\n",
            "loss: 0.002693 [25600/199980]\n",
            "loss: 0.002626 [32000/199980]\n",
            "loss: 0.004768 [38400/199980]\n",
            "loss: 0.017871 [44800/199980]\n",
            "loss: 0.006384 [51200/199980]\n",
            "loss: 0.001238 [57600/199980]\n",
            "loss: 0.020906 [64000/199980]\n",
            "loss: 0.000730 [70400/199980]\n",
            "loss: 0.019723 [76800/199980]\n",
            "loss: 0.008021 [83200/199980]\n",
            "loss: 0.015468 [89600/199980]\n",
            "loss: 0.002117 [96000/199980]\n",
            "loss: 0.039173 [102400/199980]\n",
            "loss: 0.005128 [108800/199980]\n",
            "loss: 0.000455 [115200/199980]\n",
            "loss: 0.001151 [121600/199980]\n",
            "loss: 0.001153 [128000/199980]\n",
            "loss: 0.020501 [134400/199980]\n",
            "loss: 0.001754 [140800/199980]\n",
            "loss: 0.015782 [147200/199980]\n",
            "loss: 0.000571 [153600/199980]\n",
            "loss: 0.000343 [160000/199980]\n",
            "loss: 0.027354 [166400/199980]\n",
            "loss: 0.005665 [172800/199980]\n",
            "loss: 0.003733 [179200/199980]\n",
            "loss: 0.003074 [185600/199980]\n",
            "loss: 0.000518 [192000/199980]\n",
            "loss: 0.007741 [198400/199980]\n",
            "Epoch 3\n",
            "----------------------------------\n",
            "loss: 0.021920 [    0/199980]\n",
            "loss: 0.000951 [ 6400/199980]\n",
            "loss: 0.006532 [12800/199980]\n",
            "loss: 0.002544 [19200/199980]\n",
            "loss: 0.009574 [25600/199980]\n",
            "loss: 0.000512 [32000/199980]\n",
            "loss: 0.000267 [38400/199980]\n",
            "loss: 0.000707 [44800/199980]\n",
            "loss: 0.001076 [51200/199980]\n",
            "loss: 0.014737 [57600/199980]\n",
            "loss: 0.001586 [64000/199980]\n",
            "loss: 0.003038 [70400/199980]\n",
            "loss: 0.000624 [76800/199980]\n",
            "loss: 0.001867 [83200/199980]\n",
            "loss: 0.000168 [89600/199980]\n",
            "loss: 0.018364 [96000/199980]\n",
            "loss: 0.000674 [102400/199980]\n",
            "loss: 0.021500 [108800/199980]\n",
            "loss: 0.004835 [115200/199980]\n",
            "loss: 0.004817 [121600/199980]\n",
            "loss: 0.015317 [128000/199980]\n",
            "loss: 0.025019 [134400/199980]\n",
            "loss: 0.000502 [140800/199980]\n",
            "loss: 0.021014 [147200/199980]\n",
            "loss: 0.041200 [153600/199980]\n",
            "loss: 0.045412 [160000/199980]\n",
            "loss: 0.000785 [166400/199980]\n",
            "loss: 0.002477 [172800/199980]\n",
            "loss: 0.004751 [179200/199980]\n",
            "loss: 0.000636 [185600/199980]\n",
            "loss: 0.001560 [192000/199980]\n",
            "loss: 0.000215 [198400/199980]\n",
            "Epoch 4\n",
            "----------------------------------\n",
            "loss: 0.005825 [    0/199980]\n",
            "loss: 0.004476 [ 6400/199980]\n",
            "loss: 0.000693 [12800/199980]\n",
            "loss: 0.004849 [19200/199980]\n",
            "loss: 0.015499 [25600/199980]\n",
            "loss: 0.001506 [32000/199980]\n",
            "loss: 0.012762 [38400/199980]\n",
            "loss: 0.000535 [44800/199980]\n",
            "loss: 0.000163 [51200/199980]\n",
            "loss: 0.000377 [57600/199980]\n",
            "loss: 0.000169 [64000/199980]\n",
            "loss: 0.000886 [70400/199980]\n",
            "loss: 0.000285 [76800/199980]\n",
            "loss: 0.000395 [83200/199980]\n",
            "loss: 0.000294 [89600/199980]\n",
            "loss: 0.012219 [96000/199980]\n",
            "loss: 0.001137 [102400/199980]\n",
            "loss: 0.000142 [108800/199980]\n",
            "loss: 0.006576 [115200/199980]\n",
            "loss: 0.000484 [121600/199980]\n",
            "loss: 0.000117 [128000/199980]\n",
            "loss: 0.000129 [134400/199980]\n",
            "loss: 0.000123 [140800/199980]\n",
            "loss: 0.001612 [147200/199980]\n",
            "loss: 0.001664 [153600/199980]\n",
            "loss: 0.004897 [160000/199980]\n",
            "loss: 0.011523 [166400/199980]\n",
            "loss: 0.013162 [172800/199980]\n",
            "loss: 0.000579 [179200/199980]\n",
            "loss: 0.027980 [185600/199980]\n",
            "loss: 0.010822 [192000/199980]\n",
            "loss: 0.003215 [198400/199980]\n",
            "Epoch 5\n",
            "----------------------------------\n",
            "loss: 0.000810 [    0/199980]\n",
            "loss: 0.000644 [ 6400/199980]\n",
            "loss: 0.007672 [12800/199980]\n",
            "loss: 0.000189 [19200/199980]\n",
            "loss: 0.000365 [25600/199980]\n",
            "loss: 0.014159 [32000/199980]\n",
            "loss: 0.000053 [38400/199980]\n",
            "loss: 0.000359 [44800/199980]\n",
            "loss: 0.000913 [51200/199980]\n",
            "loss: 0.000143 [57600/199980]\n",
            "loss: 0.003808 [64000/199980]\n",
            "loss: 0.009329 [70400/199980]\n",
            "loss: 0.000284 [76800/199980]\n",
            "loss: 0.000987 [83200/199980]\n",
            "loss: 0.003921 [89600/199980]\n",
            "loss: 0.000105 [96000/199980]\n",
            "loss: 0.001232 [102400/199980]\n",
            "loss: 0.001249 [108800/199980]\n",
            "loss: 0.008246 [115200/199980]\n",
            "loss: 0.016226 [121600/199980]\n",
            "loss: 0.000519 [128000/199980]\n",
            "loss: 0.000169 [134400/199980]\n",
            "loss: 0.000604 [140800/199980]\n",
            "loss: 0.000083 [147200/199980]\n",
            "loss: 0.032349 [153600/199980]\n",
            "loss: 0.005329 [160000/199980]\n",
            "loss: 0.000166 [166400/199980]\n",
            "loss: 0.000191 [172800/199980]\n",
            "loss: 0.003153 [179200/199980]\n",
            "loss: 0.010394 [185600/199980]\n",
            "loss: 0.000080 [192000/199980]\n",
            "loss: 0.000145 [198400/199980]\n",
            "Done!\n",
            "CPU times: user 27min 23s, sys: 40.5 s, total: 28min 3s\n",
            "Wall time: 29min 47s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for t in range(epochs):\n",
        "    print('Epoch {}\\n----------------------------------'.format(t+1))\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, converter)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сохранение модели в файл"
      ],
      "metadata": {
        "id": "YhnirjFqK_eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'crnn.pth'\n",
        "torch.save(model.state_dict(), MODEL_PATH)"
      ],
      "metadata": {
        "id": "Aq-7rkSmmQec"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подсчет метрик"
      ],
      "metadata": {
        "id": "RZFJ2TxBIDJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn, converter):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    cer = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            batch_size = images.size(0)\n",
        "            labels, labels_length = converter.encode(labels)\n",
        "\n",
        "            preds = model(images).log_softmax(2)\n",
        "            ctc_preds = torch.permute(preds, (1, 0, 2))\n",
        "            preds_length = torch.IntTensor([ctc_preds.size(0)] * batch_size).to(device)\n",
        "\n",
        "            preds = converter.clean(preds.argmax(2), blank=0)\n",
        "\n",
        "            test_loss += loss_fn(ctc_preds, labels, preds_length, labels_length).item()\n",
        "            correct += (preds == labels).all(dim=1).float().sum().item()\n",
        "            cer += char_error_rate(preds, labels)\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    cer /= num_batches\n",
        "    correct /= size\n",
        "    print('Test Error:\\nAccuracy: {:>0.1f}%, Avg loss: {:>8f}, Avg Char Error Rate: {:>8f}'.format(100*correct, test_loss, cer))"
      ],
      "metadata": {
        "id": "IYt2YcN-IuYX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подгрузка модели"
      ],
      "metadata": {
        "id": "PT4G4QquLKPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'crnn.pth'\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbezwFgIGntE",
        "outputId": "0e3ae279-2d0a-498c-d4b7-e930882fd435"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обзор метрик"
      ],
      "metadata": {
        "id": "czIz-L-ELOfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(train_dataloader, model, loss_fn, converter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11q_thb7o0gR",
        "outputId": "faaf24b6-ad82-4bab-95a4-cc575aa4516e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error:\n",
            "Accuracy: 99.7%, Avg loss: 0.001905, Avg Char Error Rate: 0.000489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(test_dataloader, model, loss_fn, converter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7_2b5KVpfEh",
        "outputId": "eabbe694-9249-435f-9aca-494d6dfe8305"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error:\n",
            "Accuracy: 97.3%, Avg loss: 0.020395, Avg Char Error Rate: 0.004293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обученная нейронная сеть показывает достаточно высокое качество как и на выборке для обучения, так и для тестовой"
      ],
      "metadata": {
        "id": "5IMdUNOVLRy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ ошибок модели"
      ],
      "metadata": {
        "id": "FnRT1S7hwt0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_worst_samples(dataloader, model, converter, n_samples=10):\n",
        "    batch_size = dataloader.batch_size\n",
        "    metrics_buffer = torch.zeros(n_samples).to(device)\n",
        "    images_buffer = torch.zeros((10, 32, 100)).to(device)\n",
        "    preds_buffer = [[]] * 10\n",
        "    labels_buffer = [''] * 10\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, raw_labels in dataloader:\n",
        "            batch_size = images.size(0)\n",
        "            \n",
        "            labels, labels_length = converter.encode(raw_labels)\n",
        "\n",
        "            raw_preds = model(images).log_softmax(2)\n",
        "            preds = converter.clean(raw_preds.argmax(2), blank=0)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                metric = char_error_rate([preds[i]], [labels[i]]).item()\n",
        "                if metric > metrics_buffer.min().item():\n",
        "                    argmin = metrics_buffer.argmin().item()\n",
        "                    metrics_buffer[argmin] = metric\n",
        "                    images_buffer[argmin] = images[i]\n",
        "                    preds_buffer[argmin] = converter.decode(raw_preds.argmax(2)[i])\n",
        "                    labels_buffer[argmin] = raw_labels[i]\n",
        "\n",
        "    return metrics_buffer, images_buffer, preds_buffer, labels_buffer"
      ],
      "metadata": {
        "id": "IOV2fRq-p-bH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим 10 наблюдений с наибольшими ошибками на выборке для тестирования"
      ],
      "metadata": {
        "id": "cTRUeVVYLgMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst_samples = get_worst_samples(test_dataloader, model, converter)\n",
        "worst_samples = list(worst_samples)\n",
        "for i in range(len(worst_samples)):\n",
        "    if isinstance(worst_samples[i], torch.Tensor):\n",
        "        worst_samples[i] = worst_samples[i].cpu().numpy()\n",
        "\n",
        "metrics, images, preds, labels = worst_samples"
      ],
      "metadata": {
        "id": "W8bxrf074Raf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(metrics)):\n",
        "    print('Image: {}\\nCER: {:8f}\\nModel Prediction: {}\\nLabel: {}' \\\n",
        "          .format(i, metrics[i], preds[i], labels[i]))\n",
        "    cv2_imshow(images[i])\n",
        "    print('=' * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "34Y1metP4yRf",
        "outputId": "4efcb3ef-f848-4d2b-a153-5709a197a238"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 0\n",
            "CER: 0.428571\n",
            "Model Prediction: ['皖', '-', '-', '-', 'A', '-', 'L', '-', '-', '6', '-', '-', '9', '-', '-', '-', '1', '-', '-', '5', '-', '-', 'E', '-']\n",
            "Label: 皖AJ915C\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F78AA1B2850>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 1\n",
            "CER: 0.428571\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', 'A', '-', '-', '-', 'N', '-', '-', '8', '-', '-', '3', '-', '-', '-', '3', '-', '-', 'T', '-']\n",
            "Label: 皖AN866B\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F7914CD96A0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 2\n",
            "CER: 0.571429\n",
            "Model Prediction: ['浙', '-', '-', '-', '-', '-', '1', '-', '-', '7', '-', '-', '-', 'Q', '-', '-', '0', '-', '-', 'M', '-', '-', '9', '-']\n",
            "Label: 皖AMQ059\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F5B0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 3\n",
            "CER: 0.571429\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', 'A', '-', '-', '-', '-', 'A', '-', '-', '9', '-', '-', '-', '5', '-', '-', '-', '9', '-', '-']\n",
            "Label: 皖AK927W\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F490>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 4\n",
            "CER: 0.571429\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', 'A', '-', '-', '-', '4', '-', '-', 'W', '-', '-', '3', '-', '-', '5', '-', '-', '-', 'X', '-']\n",
            "Label: 皖A2W003\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F3D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 5\n",
            "CER: 0.571429\n",
            "Model Prediction: ['浙', '-', '-', '-', '-', 'A', '-', '-', '-', 'R', 'R', '-', '-', '1', '-', '-', 'Q', '-', '-', '7', '-', '-', '0', '-']\n",
            "Label: 皖AB1930\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F5B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAgCAAAAADBQILyAAAIBUlEQVR4nCWWSY8c13aEI865eTMrq7qmbjanJkXx6QFP8gAv/Kf9M7zyzisDBmRRM0WR6rmrqyoz7z3hRa9jEUAAge/jt2cSEgIPCuS6H0ZK7W1eeYUvaonGiCOFUk0nTqseOsjQQOHJbSejdq/2H9frW7SMfW1awRRK7aHM8iwhrZ3UBMPk7sl6G8OscPldvrseP1mTHpV4MPMAeElLd5EJc7tDgmgcSWrCYfNVPv5WDIkTSPexAN2iyw4lu060AYYHUYBrFDFYf9rp8s8DKRIUoJlBeyNGHuUkHAWAQIQmXk1ftTJGAN74MBWZCaWwNSGlo1ElQEiGqAKk2m/StFhWq4kmqA+pgGIIRilAJIZACgDNCVfN2YO11hGEhJDCEkeklAQICsGCYAiERtl0eKzVinWlwulRakUKogBGQUGYRCIIJNdh8JYVAMEAwmiypi1Nq2QtqyjVCEGqQQUcx11cXtckp2LCoyxNrDAC3RiNTc6gRAkko8mpfLhsY5wAAyF02kuENcaENESBmSABFiQEcqbb38v1vnUJ4YkJqPVpGwFpOR7boIR+h9VYRCbzxTId36FOn4uM6zO/uR8iLC9qMCVJTsEotA8g85i75v6ull33/E7AYbm0fozhpoAFYPXls8uolSBivXixe7y/s6vu/XeNh1Uc/rNCi+fv5zeff78N6052ExNDbbc3peYBBMQ8br+b//RDM2SbAlY5//qUY9TL29t9hVj6szcPjOoE/J8vEPufayHckyX8sbqbmmN+/nW/nOX9LdNsfpiUkjCfTVB38mlXE4O1ybN23gSbeKyCmvWbY78M9t20EwE125ffKyIBevni7NbXuL9sfP9bk/LjevmpOvr32x9/nS//ffx4P9SAEqPpZjvG/PzxEI2MhYuTNPeRIgUR5vufU24W7xYfEYSN/SxTkFV7V/7vF/7TyflN5/dXyNi8w42KVqc3P968fP3V9vMUtYApL7lur0vulzMvjRDFFydcNkcHBAAi44PYftvNvBDi1JgzT9sd3z379adPsXq/ZRu7Isbr2a/XVuz0/oe74x/29vUHmQCYt3lxZtP5ll/9I5NktVmTelU9/Qx0IqLuP5f5hiGBBoCMsDd+c9Pa93ez5cNjtJ1vX/lvd6Z0OrvyfLwbN6ALhOWUm27e5Tw/e/tMgKPpbx8OJ4QoMzMSxc3513jyTC4CDoKcwjoA4jTlfCw1yvjt85+GVOj9unHwOLCSoJiazG6xQVs+N/M5AHrTNtY0pGAmoFb5GMZddAvIEI2xAjxG7iUhDbVNRja7/hl//5KObOyhREYxuKGGkFJKeb6u+f6n/nUAMM9di+QUGCYKgmmydrieXVkAQJUBUrE+qszva244GzJfbepfuwVBqBJeG3jSKMKYl3zIuSl312FBWeo675rGQUEULCEC0mb9+CgCwNVxAUtdUpUFUmXXpNwct/8o7IwgTBJEU4ACYOJJ/d9c/vu4XV3fZ29Sar11TwRAoxFEBZjerD8fRDwVE2h8uj62h/L4prXJq8azVwPfnhbAvAqEWZUZBCSRcTxo/nw1fjm0YKO+r/vNy58nQCJER/rbAxbvTz4MCIA0FJAT4741O5y/O90XHcq8PV7Ev7T/5e7tAEoJNUyimCSwDJqf62a3nxCOmT0+np1kQVKqQeaz1V1qN7PrEQBIC0GR0nD99bub/ek3/eUQbnH/w12ebTbXZqecHyabGc0oE1IYlWfX4y7VoIDCGW6OozdVKp4HNd73g2MVv90VGmBOVDOLtLs8vFWxba17eI3Pu19Wr16+vaeiArKWOYHWoSYrtTlp6+HXwMNEoKQ5rocp5RGy7fbzpVx1qiyaL0kzS6nrawIdzf6Ps23HYvMR7Thp5LVdvPh+KmM8sSxMnm+7Lmm3f1GDGuCLMoaX3OluFNuhUmcXcT86rn4/2Hbz/OJDFRxMpCd6LOwXvXl3NZ1fk7AA4nA7dR61KiA65JotH/tVOh6RlvPDrGNufvwYvt76dDru2T2CD7ebu8Fc93/cpy8Xb8+WD6AVuJlbCJqm7z/9j/4VH2sz9YRwHIfT/sZUJQu4EN2LruvTom2bydvNHOZd3yzzdj17O6g7HR729tehenbAVS81ee4UKNksWY5iShqvvti/7e+nqpwRKofdN8svq16LoQm6EM3Z60B632ybx1FNqmWaX8zO02KbvCSP9X430PxgK2h2ji/4sj7/MwIHGN0TKYwR0t9Xv47LqXu1nMb9TS0PadXuLo9Dn9k3C/S5ldIFnScr5nzcD2+Lb7xfxqA25We17iPxoK6/OCnT2nTy7boWv9ynqW1TK3GWJPx99edbt/WLRZ2ON/XlfLM8entmKZYYO8eYxWQvFco5pWFxXA1ji8RSIbOuSzvlVIPYjDHtY9Z982aK49X0bj2x6cYyzZpkzXm6OKc/S4Xhr6Nr/rb+8/z07OZ4u14cXns3CUjWAKpdKLeL9kTY41iEOh3NmgCTWfZawFAEVtL+hNtn7SblUgfRvDedWQPNqYlW1V28ms11+ni422wfiTMjwP8IAJKAQEPoKDxpadAZZHjfX1cwUxjDolSkeRmYJB2ZWyk0STHvnjg6jXnI9DGmkzxOnO+zmJonGwwqINElwikKwUwwVB7coaAbQ+oy9rvcTQHQ6OwQ2FfKAiAIz9FaQi+xupkaEMkByAFAGoEAgfZJXPlEeMCe4goTTMxK2QMIZ+tHGZokJUJAwA3ikx6IVCWA/wc4gezF6WPI+AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 6\n",
            "CER: 0.428571\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', '-', 'A', '-', '-', 'F', '-', '-', '8', '-', '-', '9', '-', '-', 'R', '-', '-', '7', '-', '-']\n",
            "Label: 皖AF888S\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F490>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 7\n",
            "CER: 0.571429\n",
            "Model Prediction: ['皖', '-', '-', '-', 'A', '-', '-', '8', '-', '-', 'H', '-', '3', '-', '-', '3', '-', '6', 'A', '-', '-', '-', '1', '-']\n",
            "Label: 皖ABJ356\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F3D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 8\n",
            "CER: 0.428571\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', 'A', '-', '-', '-', 'L', '-', '-', '-', '5', '-', '-', '7', '-', '-', 'Z', '-', '-', '7', '-']\n",
            "Label: 皖ALG722\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F5B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAgCAAAAADBQILyAAAFCklEQVR4nHWW23LcyBFET1Y3LkNRWoe/09/tcIQdtlZLkTNodKUfGgDJlT3zgkuirlnZpb/x+SeMhQW68ctP+Evq1+cgf8anYZktoH4CWhqGJGQs/8meAP8vF+PNB7wXISF+cSImoCGiyvw5Ytfy/3z8gldUY2SgGuE4PhVFJpusar3Hd36uCjh+9WOmRAOPI6+8DBASyB5lsD2gn8KysEcKIzif+MuFPj4ZRfM7IIYxaVzLmCDFlRsRRoHCMjIGaSAtCTsSEknnR8Lke5j1yZvlqdybn40eLLXmo/WrUstT/myYqVrZ5mUmRd+JzGmeAjny0bY2zdPeAhK4hWXJ2ADVscqeS713K1nKOtUsW0uPuqXziExIt7rMz2Eev4OY5ykseBG6TdOcDXhBPIVlLH6OTOSbTC1BN+RtXmp1UXn70JHjwqFlWurdsleH/1HWOSx7Bi3TMmVB/mnlUjxq/ZoC6vP8sKCU1d+79GBa610lB/nIeLqJZpRW11bbjzdZsRrNfjyWtc7Lv1xr7rv3Ps/1S4rvBuYv+epjTly66Q/8Th0DytF2YckjIaEPdEaGTJTItHYQyrISoXd2VTCo33FYWDYRY4pkhhXpxDvrcIkcDMTI8tEhbqDwqLA9OHsOI5ByIotp7T+8uKVMXVCS5eqK5qcaYdzvzlJWHPPKH710pgmrPD+57ablUmt0l+hDuxw7FoNuMghRzZGvxt8H/xNKSfmecpFl26lDMlWrWyLLRupIp3ZpjOgRbtrkYR75xGt0JU3Z1xhd67uEUfhQk/hW8yXlYE+RoDH81RC7Yk53Iygie9e0HXm5SNkPubJB9Cy6ZU+wFSLDYBVVeXt4ysxSVB4SF7tqb/F029qjg6nhrZd5WvPoQ630NnOKn+j/nOf5qfW9CzOVvSGQlrlsrWV2o+dprS/XhIXlYzolCedRoavXPmg2yJWDePbJHHNwT3mqiGSciku7AhNiDMWYEEJc7BM+2/cuAB4aOQCnP9uijNcyzvo+J3PdhEGw79NS8wcoSv9g9oPql6W8PYb0e3iMfq+7LZevX/ofXeu+T9Oy9Pb9/dyphgBDEAatAs1L5MvlA8V5mXKVSDJ0UEfRjdDz0t86mDwmPq/QKhKlWyERkNNkaVnmy0laZ9lRWqiX0RM7EofAgW91f+1V1lEYW0AkUB8qP+qt3vsqlj2+PbNtqdheT26oKtqWIqYS/Oe3tfyup1v+bFujrHN/a5vVb1/brufWpLRhs1aA3ADqPefsVdGRC3bz9tgfz7Wcfe05P/31gRTF+660FnK79hqH4jG7W7bW36D//f1k1mhLfctu4dKON1tr93zJrzEqZDnrum7gmF9fNqN8yu1tn31yDStIkMnH0NWLmkdP+tZrf2yKnvXV8fbaMvlWGvt+INvLXTuY19boP14tenfLhOZWijXHorcNkT2S9H0r5XAyDq3iXZEw33EnmxvEykaeLG770fQm5LaN+LsM7JSVCtV9wBPkxnQSS4DrGC38U7iX0e18s9jPE+VNgFLUsVn4ovZ1+2kR82HyulUdQx29JxBYMchxVDtRG3koYuxPSlmufYisTwW/tIfz6ZVLvaM7EH8BWr+/hQeKWiFuJ9rXJjYOSu/C03TtGQPPif28Q9ePm/isdzGUMzLPY1jvZLHqCvy8jv5hUK19sBQfzbquZ4YkU/2Qdr9m4VpyBzTz38jzqP75SvjxnonLRyf6L6cwdQ2NyYg0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Image: 9\n",
            "CER: 0.428571\n",
            "Model Prediction: ['皖', '-', '-', '-', '-', '-', 'H', '-', '-', '-', 'Z', '-', '-', '1', '-', '2', '2', '-', 'V', '-', '-', '-', '1', '-']\n",
            "Label: 鲁M712V1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x32 at 0x7F790D29F490>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Большинство ошибок в выделенных изображениях появляются из-за нечеткости изображения или наличия грязи/снега на номерах.\n",
        "\n",
        "Попробовать решить данную проблему можно дообучением на таких данных. Еще можно немного улучшить контрастность символов с помощью библиотеки cv2."
      ],
      "metadata": {
        "id": "Dnk6Hr4DI8cC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jPpGeM-QJwn4",
        "99PP2wfFKMgi",
        "iHHzo-6yKWNo",
        "xqkwxI9QKrpg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}